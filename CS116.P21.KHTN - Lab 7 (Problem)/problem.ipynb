{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# CÁC PHƯƠNG PHÁP BOOSTING VÀ ENSEMBLE"], "id": "c88cfe80-9d3a-40f8-af4f-a3caa7561832"}, {"cell_type": "markdown", "metadata": {}, "source": ["Trong notebook này, chúng ta sẽ tìm hiểu về các phương pháp không nằm trong bộ sklearn mà thường được sử dụng để thi các cuộc thi trên Kaggle và đạt được độ chính xác cao. Cụ thể, chúng ta sẽ tập trung vào các thuật toán Gradient Boosting như ***XGBoost***, ***LightGBM*** và ***CatBoost***. Chúng ta cũng sẽ tìm hiểu về cách kết hợp chúng bằng kỹ thuật Ensemble để cải thiện hiệu suất dự đoán."], "id": "adbbb7ac-8733-4321-b340-408a691fc5f7"}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1. Tải dữ liệu"], "id": "097e9d15-83b1-44bb-9090-48ef823c58af"}, {"cell_type": "markdown", "metadata": {}, "source": ["Trong bài này ta sẽ sữ dụng dữ liệu về ung thư vú được tải từ hàm `load_breast_cancer()` của module `sklearn.datasets`."], "id": "0435001d-55f6-420e-8a4c-b12bdcec07fd"}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import load_breast_cancer\n", "import pandas as pd\n", "\n", "# Tải dữ liệu\n", "breast_cancer = load_breast_cancer()\n", "X = breast_cancer.data\n", "y = breast_cancer.target\n", "\n", "# Tạo dataframe từ dữ liệu để dễ dàng quan sát\n", "df = pd.DataFrame(data=X, columns=breast_cancer.feature_names)\n", "df[\"target\"] = y"], "id": "0ba52c47-5e0f-4a5d-b7ca-5757478b4e3f"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>mean radius</th>\n", "      <th>mean texture</th>\n", "      <th>mean perimeter</th>\n", "      <th>mean area</th>\n", "      <th>mean smoothness</th>\n", "      <th>mean compactness</th>\n", "      <th>mean concavity</th>\n", "      <th>mean concave points</th>\n", "      <th>mean symmetry</th>\n", "      <th>mean fractal dimension</th>\n", "      <th>...</th>\n", "      <th>worst texture</th>\n", "      <th>worst perimeter</th>\n", "      <th>worst area</th>\n", "      <th>worst smoothness</th>\n", "      <th>worst compactness</th>\n", "      <th>worst concavity</th>\n", "      <th>worst concave points</th>\n", "      <th>worst symmetry</th>\n", "      <th>worst fractal dimension</th>\n", "      <th>target</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>17.99</td>\n", "      <td>10.38</td>\n", "      <td>122.80</td>\n", "      <td>1001.0</td>\n", "      <td>0.11840</td>\n", "      <td>0.27760</td>\n", "      <td>0.3001</td>\n", "      <td>0.14710</td>\n", "      <td>0.2419</td>\n", "      <td>0.07871</td>\n", "      <td>...</td>\n", "      <td>17.33</td>\n", "      <td>184.60</td>\n", "      <td>2019.0</td>\n", "      <td>0.1622</td>\n", "      <td>0.6656</td>\n", "      <td>0.7119</td>\n", "      <td>0.2654</td>\n", "      <td>0.4601</td>\n", "      <td>0.11890</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>20.57</td>\n", "      <td>17.77</td>\n", "      <td>132.90</td>\n", "      <td>1326.0</td>\n", "      <td>0.08474</td>\n", "      <td>0.07864</td>\n", "      <td>0.0869</td>\n", "      <td>0.07017</td>\n", "      <td>0.1812</td>\n", "      <td>0.05667</td>\n", "      <td>...</td>\n", "      <td>23.41</td>\n", "      <td>158.80</td>\n", "      <td>1956.0</td>\n", "      <td>0.1238</td>\n", "      <td>0.1866</td>\n", "      <td>0.2416</td>\n", "      <td>0.1860</td>\n", "      <td>0.2750</td>\n", "      <td>0.08902</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>19.69</td>\n", "      <td>21.25</td>\n", "      <td>130.00</td>\n", "      <td>1203.0</td>\n", "      <td>0.10960</td>\n", "      <td>0.15990</td>\n", "      <td>0.1974</td>\n", "      <td>0.12790</td>\n", "      <td>0.2069</td>\n", "      <td>0.05999</td>\n", "      <td>...</td>\n", "      <td>25.53</td>\n", "      <td>152.50</td>\n", "      <td>1709.0</td>\n", "      <td>0.1444</td>\n", "      <td>0.4245</td>\n", "      <td>0.4504</td>\n", "      <td>0.2430</td>\n", "      <td>0.3613</td>\n", "      <td>0.08758</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>11.42</td>\n", "      <td>20.38</td>\n", "      <td>77.58</td>\n", "      <td>386.1</td>\n", "      <td>0.14250</td>\n", "      <td>0.28390</td>\n", "      <td>0.2414</td>\n", "      <td>0.10520</td>\n", "      <td>0.2597</td>\n", "      <td>0.09744</td>\n", "      <td>...</td>\n", "      <td>26.50</td>\n", "      <td>98.87</td>\n", "      <td>567.7</td>\n", "      <td>0.2098</td>\n", "      <td>0.8663</td>\n", "      <td>0.6869</td>\n", "      <td>0.2575</td>\n", "      <td>0.6638</td>\n", "      <td>0.17300</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>20.29</td>\n", "      <td>14.34</td>\n", "      <td>135.10</td>\n", "      <td>1297.0</td>\n", "      <td>0.10030</td>\n", "      <td>0.13280</td>\n", "      <td>0.1980</td>\n", "      <td>0.10430</td>\n", "      <td>0.1809</td>\n", "      <td>0.05883</td>\n", "      <td>...</td>\n", "      <td>16.67</td>\n", "      <td>152.20</td>\n", "      <td>1575.0</td>\n", "      <td>0.1374</td>\n", "      <td>0.2050</td>\n", "      <td>0.4000</td>\n", "      <td>0.1625</td>\n", "      <td>0.2364</td>\n", "      <td>0.07678</td>\n", "      <td>0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>5 rows × 31 columns</p>\n", "</div>"], "text/plain": ["   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n", "0        17.99         10.38          122.80     1001.0          0.11840   \n", "1        20.57         17.77          132.90     1326.0          0.08474   \n", "2        19.69         21.25          130.00     1203.0          0.10960   \n", "3        11.42         20.38           77.58      386.1          0.14250   \n", "4        20.29         14.34          135.10     1297.0          0.10030   \n", "\n", "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n", "0           0.27760          0.3001              0.14710         0.2419   \n", "1           0.07864          0.0869              0.07017         0.1812   \n", "2           0.15990          0.1974              0.12790         0.2069   \n", "3           0.28390          0.2414              0.10520         0.2597   \n", "4           0.13280          0.1980              0.10430         0.1809   \n", "\n", "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n", "0                 0.07871  ...          17.33           184.60      2019.0   \n", "1                 0.05667  ...          23.41           158.80      1956.0   \n", "2                 0.05999  ...          25.53           152.50      1709.0   \n", "3                 0.09744  ...          26.50            98.87       567.7   \n", "4                 0.05883  ...          16.67           152.20      1575.0   \n", "\n", "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n", "0            0.1622             0.6656           0.7119                0.2654   \n", "1            0.1238             0.1866           0.2416                0.1860   \n", "2            0.1444             0.4245           0.4504                0.2430   \n", "3            0.2098             0.8663           0.6869                0.2575   \n", "4            0.1374             0.2050           0.4000                0.1625   \n", "\n", "   worst symmetry  worst fractal dimension  target  \n", "0          0.4601                  0.11890       0  \n", "1          0.2750                  0.08902       0  \n", "2          0.3613                  0.08758       0  \n", "3          0.6638                  0.17300       0  \n", "4          0.2364                  0.07678       0  \n", "\n", "[5 rows x 31 columns]"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["# Xem qua một vài dòng dữ liệu\n", "df.head()"], "id": "2e88e77f-cbae-4f7a-8461-cb1a2852fdcf"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<class 'pandas.core.frame.DataFrame'>\n", "RangeIndex: 569 entries, 0 to 568\n", "Data columns (total 31 columns):\n", " #   Column                   Non-Null Count  Dtype  \n", "---  ------                   --------------  -----  \n", " 0   mean radius              569 non-null    float64\n", " 1   mean texture             569 non-null    float64\n", " 2   mean perimeter           569 non-null    float64\n", " 3   mean area                569 non-null    float64\n", " 4   mean smoothness          569 non-null    float64\n", " 5   mean compactness         569 non-null    float64\n", " 6   mean concavity           569 non-null    float64\n", " 7   mean concave points      569 non-null    float64\n", " 8   mean symmetry            569 non-null    float64\n", " 9   mean fractal dimension   569 non-null    float64\n", " 10  radius error             569 non-null    float64\n", " 11  texture error            569 non-null    float64\n", " 12  perimeter error          569 non-null    float64\n", " 13  area error               569 non-null    float64\n", " 14  smoothness error         569 non-null    float64\n", " 15  compactness error        569 non-null    float64\n", " 16  concavity error          569 non-null    float64\n", " 17  concave points error     569 non-null    float64\n", " 18  symmetry error           569 non-null    float64\n", " 19  fractal dimension error  569 non-null    float64\n", " 20  worst radius             569 non-null    float64\n", " 21  worst texture            569 non-null    float64\n", " 22  worst perimeter          569 non-null    float64\n", " 23  worst area               569 non-null    float64\n", " 24  worst smoothness         569 non-null    float64\n", " 25  worst compactness        569 non-null    float64\n", " 26  worst concavity          569 non-null    float64\n", " 27  worst concave points     569 non-null    float64\n", " 28  worst symmetry           569 non-null    float64\n", " 29  worst fractal dimension  569 non-null    float64\n", " 30  target                   569 non-null    int64  \n", "dtypes: float64(30), int64(1)\n", "memory usage: 137.9 KB\n"]}], "source": ["# Xem kiểu dữ liệu và số giá trị rỗng của mỗi cột\n", "df.info()"], "id": "e5de6f57-defb-468a-8064-fdaf8e7c1f84"}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2. Tiền xử lí dữ liệu"], "id": "2e6d3ab6-23ec-4fa5-ac07-f5201de5dbdd"}, {"cell_type": "markdown", "metadata": {}, "source": ["Vì dữ liệu ở các cột là kiểu số và không có giá trị rỗng nên ta chỉ cần chuẩn hóa dữ liệu sử dụng lớp `MinMaxScaler` từ module `sklearn.preprocessing`."], "id": "791ee46b-958b-483c-9311-9dea986b0fc6"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import MinMaxScaler\n", "\n", "scaler = MinMaxScaler()\n", "X = scaler.fit_transform(X)"], "id": "152fef82-a2cc-4900-98a0-220987308c04"}, {"cell_type": "markdown", "metadata": {}, "source": ["Sau đó ta tiến hành chia tập dữ liệu thành 2 phần: tập train và tập test sử dụng hàm `train_test_split()` từ module `sklearn.model_selection` là xong phần chuẩn bị dữ liệu."], "id": "e2a44a44-956c-4bb9-b111-536b8413012f"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"], "id": "25242694-31b4-450e-a4ef-db99bfb70c84"}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3. Xây dựng các mô hình boosting"], "id": "0ad31e08-a330-4b40-9a1d-db73f44828a4"}, {"cell_type": "markdown", "metadata": {}, "source": ["Chúng ta sẽ sử dụng những mô hình boosting được dùng nhiều từ những cuộc thi về machine learning trên Kaggle vì chúng có độ chính xác cao trên những dữ liệu thuộc kiểu bảng (tabular data). Những mô hình đó không có sẵn trong thư viện `sklearn` mà từ những thư viện."], "id": "f6beaa50-4ed9-40c1-b017-7b25975a7616"}, {"cell_type": "markdown", "metadata": {}, "source": ["**Bài tập**: Hãy import 3 mô hình `XGBClassifier`, `LGBMClassifier`, `CatBoostClassifier` có sẵn lần lượt từ các thư viện `xgboost`, `lightgbm`, `catboost` (cài đặt trước đó bằng cách `pip install xgboost lightgbm catboost`) và gán vào những biến đã được khởi tạo bên dưới sao cho phù hợp. Lưu ý: Khởi tạo mỗi mô hình với tham số ***random_state=42*** đối với 2 mô hình `XGBClassifier` và `LGBMClassifier`."], "id": "724e947f-079a-406e-be29-eb3c5b5722fe"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["xgboost_clf = None\n", "lgbm_clf = None\n", "catboost_clf = None\n", "\n", "### BEGIN SOLUTION\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "### END SOLUTION"], "id": "ba443f13-7f34-49e2-bcca-bab86c1b56f7"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["assert xgboost_clf is not None and lgbm_clf is not None and catboost_clf is not None"], "id": "ec281a3c-8c71-4a14-9e16-55014560c3ba"}, {"cell_type": "markdown", "metadata": {}, "source": ["Ta tiến hành huấn luyện các mô hình trên trên tập train"], "id": "a1e3a8ff-0674-418f-bb97-e317b31f48af"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"data": {"text/plain": ["<catboost.core.CatBoostClassifier at 0x13fbca450>"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["xgboost_clf.fit(X_train, y_train)\n", "lgbm_clf.fit(X_train, y_train)\n", "catboost_clf.fit(X_train, y_train)"], "id": "5abf6d77-8146-4549-bf11-4e7308503d3e"}, {"cell_type": "markdown", "metadata": {}, "source": ["Sau khi huấn luyện thành công, ta sẽ đánh giá lần lượt từng mô hình trên tập test với metric là accuracy."], "id": "23c39007-0747-42cd-b86e-d5bc8f993a26"}, {"cell_type": "markdown", "metadata": {}, "source": ["**Bài tập**: Hãy sử dụng hàm `accuracy_score` từ module `sklearn.metrics` để tính toán độ chính xác của từng mô hình trên tập test và gán nó vào các biến đã tạo bên dưới sao cho phù hợp."], "id": "40718b18-a5aa-42a6-8cb2-c0d36f4049ac"}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["xgboost_clf_acc = None\n", "lgbm_clf_acc = None\n", "catboost_clf_acc = None\n", "\n", "### BEGIN SOLUTION\n", "\n", "\n", "\n", "\n", "\n", "### END SOLUTION"], "id": "f5cbd2d4-c46e-4ee9-bccf-14951855fb15"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": ["assert str(type(xgboost_clf_acc)) == \"<class 'numpy.float64'>\"\n", "assert str(type(lgbm_clf_acc)) == \"<class 'numpy.float64'>\"\n", "assert str(type(catboost_clf_acc)) == \"<class 'numpy.float64'>\""], "id": "cb5c72a7-16e2-493f-a3fd-ed2e9faa5aa6"}, {"cell_type": "markdown", "metadata": {}, "source": ["In độ chính xác của từng mô hình, ta thấy rằng độ chính xác của chúng là khá cao so với những mô hình phân loại mà ta sử dụng trước đó."], "id": "7596882c-ee3c-4103-9fd0-5728a96bfbd2"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["XGBClassifier Accuracy:      0.956140350877193\n", "LGBMClassifier Accuracy:     0.9649122807017544\n", "CatBoostClassifier Accuracy: 0.9736842105263158\n"]}], "source": ["print(\"XGBClassifier Accuracy:     \", xgboost_clf_acc)\n", "print(\"LGBMClassifier Accuracy:    \", lgbm_clf_acc)\n", "print(\"CatBoostClassifier Accuracy:\", catboost_clf_acc)"], "id": "5e6320bf-af82-45e1-9cda-f6207f58c46a"}, {"cell_type": "markdown", "metadata": {}, "source": ["### 4. Ensemble Methods"], "id": "52e682d9-27ec-4123-9419-029c82d72838"}, {"cell_type": "markdown", "metadata": {}, "source": ["Trong Machine Learning, ***Ensemble Methods*** là một kỹ thuật mạnh mẽ được sử dụng để cải thiện hiệu suất của các mô hình dự đoán. Thay vì sử dụng một mô hình duy nhất để thực hiện dự đoán, Ensemble Methods kết hợp kết quả từ nhiều mô hình con để đưa ra dự đoán cuối cùng. Việc này có thể giúp giảm thiểu sai số và tăng tính ổn định của dự đoán.\n", "\n", "Các phương pháp Ensemble được sử dụng rộng rãi trong các cuộc thi trên Kaggle và các ứng dụng thực tế trong thế giới thực. Dưới đây, chúng ta sẽ tìm hiểu về hai kỹ thuật Ensemble phổ biến: ***Voting Classifier*** và ***Stacking Classifier***."], "id": "b56021a5-795f-4c04-b449-39a63c55f9ae"}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 4.1. Voting Classifier"], "id": "35fc3216-4179-4985-aca7-617dc60296e5"}, {"cell_type": "markdown", "metadata": {}, "source": ["***Voting Classifier*** là một phương pháp Ensemble đơn giản nhưng hiệu quả. Nó làm việc bằng cách kết hợp kết quả dự đoán từ nhiều mô hình con khác nhau. Có hai loại chính của ***Voting Classifier***:\n", "\n", "* ***Hard Voting***: Kết quả cuối cùng là kết quả của sự bỏ phiếu đa số giữa các mô hình con. Nếu hơn một nửa các mô hình dự đoán một lớp cụ thể, lớp đó sẽ được chọn là kết quả.\n", "\n", "* ***Soft Voting***: Kết quả cuối cùng là kết quả của sự bỏ phiếu dựa trên xác suất dự đoán của các mô hình con. Nó thường làm tốt hơn so với hard voting và phù hợp khi các mô hình con có khả năng ước tính xác suất."], "id": "5247c451-76e3-4193-a901-0b27bce18af3"}, {"cell_type": "markdown", "metadata": {}, "source": ["**Bài tập**: Hãy import lớp `VotingClassifier` từ module `sklearn.ensemble` và tạo một mô hình ensemble kết hợp từ 3 mô hình boosting phía trên và gán vào biến `voting_model` bên dưới. Lưu ý: Khởi tạo mô hình **voting** với tham số ***voting=\"soft\"***, sử dụng lại các mô hình boosting đã tạo."], "id": "e88c0e2f-01b8-4eee-9b2c-78ecd3c1fbed"}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["voting_model = None\n", "\n", "### BEGIN SOLUTION\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "### END SOLUTION"], "id": "813883c3-53e1-4d81-ad48-b26270f3f3fa"}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["assert voting_model.__class__.__name__ == \"VotingClassifier\"\n", "assert len(voting_model.estimators) == 3"], "id": "0ccc1209-fbda-4712-8377-7323897d7463"}, {"cell_type": "markdown", "metadata": {}, "source": ["Ta tiến hành huấn luyện và đánh giá mô hình voting thôi nào"], "id": "4758c683-e7f2-4d49-b3c1-aa67d569e263"}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Voting Model Accuracy: 0.9736842105263158\n"]}], "source": ["from sklearn.metrics import accuracy_score\n", "\n", "voting_model.fit(X_train, y_train)\n", "print(\"Voting Model Accuracy:\",\n", "      accuracy_score(y_test, voting_model.predict(X_test)))"], "id": "ed0b1ebf-0cf1-466e-a34c-2d2caf8666d6"}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 4.2. Stacking Classifier"], "id": "37170784-3c12-46b3-99c9-be1229415b85"}, {"cell_type": "markdown", "metadata": {}, "source": ["***Stacking Classifier*** là một phương pháp Ensemble phức tạp hơn so với ***Voting Classifier***. Trong Stacking, các mô hình con được chia thành hai hoặc nhiều tầng (layers). Ở tầng đầu tiên (base layer), các mô hình con được huấn luyện trên dữ liệu huấn luyện và dự đoán trên dữ liệu kiểm tra. Sau đó, dự đoán từ các mô hình con ở tầng đầu tiên được sử dụng như đầu vào cho mô hình cấp cao hơn (meta-model) ở tầng thứ hai (meta layer) để dự đoán kết quả cuối cùng.\n", "\n", "Stacking thường cần nhiều tính toán hơn và sử dụng nhiều tài nguyên hơn so với Voting, nhưng nó có tiềm năng để tạo ra các ensemble mạnh hơn và cải thiện hiệu suất dự đoán.\n", "\n", "Cả hai kỹ thuật này đều có thể giúp cải thiện hiệu suất dự đoán của mô hình bằng cách kết hợp sức mạnh của nhiều mô hình con, tuy nhiên, bạn cần lựa chọn một trong số họ dựa trên bộ dữ liệu cụ thể và mục tiêu của bạn."], "id": "dbbed906-16f3-41a5-b461-76fae813c231"}, {"cell_type": "markdown", "metadata": {}, "source": ["**Bài tập**: Hãy import lớp `StackingClassifier` từ module `sklearn.ensemble` và tạo một mô hình ensemble kết hợp từ 3 mô hình boosting phía trên theo thứ tự: `XGBClassifier`, `LGBMClassifier`, `CatBoostClassifier` với mô hình cuối cùng để kếp hợp dự đoán (tham số final_estimator) là `XGBClassifier` và gán vào biến `stacking_model` bên dưới. Lưu ý: sử dụng lại các mô hình boosting đã tạo."], "id": "a4ba4667-00b2-449f-b784-66d1850da06f"}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["stacking_model = None\n", "\n", "### BEGIN SOLUTION\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "### END SOLUTION"], "id": "0acc3c73-56e5-4a1c-8739-95af267c97cc"}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["assert stacking_model.__class__.__name__ == \"StackingClassifier\"\n", "assert len(stacking_model.estimators) == 3"], "id": "6091891e-bfb1-4a64-ba47-620bf5484959"}, {"cell_type": "markdown", "metadata": {}, "source": ["Ta tiến hành huấn luyện và đánh giá mô hình stacking tương tự như trên."], "id": "be188065-65db-4c07-9dd8-52e5bef60923"}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Stacking Model Accuracy: 0.9649122807017544\n"]}], "source": ["stacking_model.fit(X_train, y_train)\n", "print(\"Stacking Model Accuracy:\",\n", "      accuracy_score(y_test, stacking_model.predict(X_test)))"], "id": "58b8f414-866e-459c-8d20-604c1f91da45"}, {"cell_type": "markdown", "metadata": {}, "source": ["### 5. Kết Luận\n", "\n", "Trong notebook này, chúng ta đã tìm hiểu về các phương pháp không nằm trong bộ sklearn như XGBoost, LightGBM và CatBoost, những mô hình thông dụng trong các cuộc thi trên Kaggle để đạt được độ chính xác cao. Chúng ta đã thực hiện các bước cơ bản từ tiền xử lý dữ liệu, huấn luyện các mô hình, và đánh giá hiệu suất trên tập kiểm tra.\n", "\n", "Một số điểm quan trọng cần lưu ý:\n", "- XGBoost, LightGBM và CatBoost là các mô hình mạnh mẽ có thể mang lại kết quả tốt trên nhiều loại dữ liệu khác nhau.\n", "- Lựa chọn mô hình thường dựa trên thử nghiệm và kiến thức về từng thuật toán. XGBoost thường là một lựa chọn tốt để bắt đầu, nhưng LightGBM và CatBoost có thể mang lại kết quả tốt hơn trong một số trường hợp.\n", "- Kỹ thuật Ensemble, như sử dụng `VotingClassifier`, có thể cải thiện độ chính xác của mô hình bằng cách kết hợp sức mạnh của các mô hình khác nhau.\n", "\n", "Hãy nhớ rằng để thành công trên Kaggle hoặc trong bất kỳ dự án Machine Learning nào, việc thử nghiệm và tinh chỉnh là quan trọng. Hãy luôn cân nhắc và tùy chỉnh phương pháp của mình để phù hợp với bài toán cụ thể và dữ liệu của bạn.\n", "\n", "Chúc các bạn thành công trong việc tham gia các cuộc thi trên Kaggle và trong việc áp dụng Machine Learning vào thực tế!\n"], "id": "a7a7c9e7-bfe8-4999-9e96-d54d921001ed"}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.12"}}, "nbformat": 4, "nbformat_minor": 5}